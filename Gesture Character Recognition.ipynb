{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8632836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f81e42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: requests in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (4.1.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (1.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\tanishka\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14e3aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import copy\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4112bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect1_tl = (620,240)\n",
    "rect2_tl = (620,290)\n",
    "rect3_tl = (620,340)\n",
    "rect4_tl = (580,320)\n",
    "rect5_tl = (660,320)\n",
    "\n",
    "height = 30\n",
    "width = 30\n",
    "\n",
    "# Shift all the rectangles to the left by reducing the 'x' coordinate\n",
    "shift_amount_x = 350\n",
    "shift_amount_y = 70 # You can adjust this value based on your needs\n",
    "rect1_tl = (rect1_tl[0] - shift_amount_x, rect1_tl[1] - shift_amount_y)\n",
    "rect2_tl = (rect2_tl[0] - shift_amount_x, rect2_tl[1] - shift_amount_y)\n",
    "rect3_tl = (rect3_tl[0] - shift_amount_x, rect3_tl[1] - shift_amount_y)\n",
    "rect4_tl = (rect4_tl[0] - shift_amount_x, rect4_tl[1] - shift_amount_y)\n",
    "rect5_tl = (rect5_tl[0] - shift_amount_x, rect5_tl[1] - shift_amount_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db71870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layer\n",
    "        self.conv1 = nn.Conv2d(1, 16,  3,padding = 1 )\n",
    "        #Convultion Sees 28*28*16\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3,padding = 1)\n",
    "        #convultion sees 14*14*32\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3,padding = 1)\n",
    "        #convultion sees 7*7*64\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64*3*3,256)\n",
    "        self.fc2 = nn.Linear(256,26)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        # max pooling layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1,64*3*3)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32829715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHistogram(frame):\n",
    "    roi1 = frame[rect1_tl[1]:rect1_tl[1]+width,rect1_tl[0]:rect1_tl[0]+height]\n",
    "    roi2 = frame[rect2_tl[1]:rect2_tl[1]+width,rect2_tl[0]:rect2_tl[0]+height]\n",
    "    roi3 = frame[rect3_tl[1]:rect3_tl[1]+width,rect3_tl[0]:rect3_tl[0]+height]\n",
    "    roi4 = frame[rect4_tl[1]:rect4_tl[1]+width,rect4_tl[0]:rect4_tl[0]+height]\n",
    "    roi5 = frame[rect5_tl[1]:rect5_tl[1]+width,rect5_tl[0]:rect5_tl[0]+height]\n",
    "    roi = np.concatenate((roi1,roi2,roi3,roi4,roi5),axis = 0)\n",
    "    roi_hsv = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    return cv2.calcHist([roi_hsv],[0,1],None,[180,256],[0,180,0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3b6e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawRectangles(frame = 0):\n",
    "    frame_with_rect = frame\n",
    "    cv2.rectangle(frame_with_rect,rect1_tl,tuple(np.array(rect1_tl)+np.array((height,width))),(0,0,255),1)\n",
    "    cv2.rectangle(frame_with_rect,rect2_tl,tuple(np.array(rect2_tl)+np.array((height,width))),(0,0,255),1)\n",
    "    cv2.rectangle(frame_with_rect,rect3_tl,tuple(np.array(rect3_tl)+np.array((height,width))),(0,0,255),1)\n",
    "    cv2.rectangle(frame_with_rect,rect4_tl,tuple(np.array(rect4_tl)+np.array((height,width))),(0,0,255),1)\n",
    "    cv2.rectangle(frame_with_rect,rect5_tl,tuple(np.array(rect5_tl)+np.array((height,width))),(0,0,255),1)\n",
    "    return frame_with_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3312109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMask(frame, histogram):\n",
    "    frame_hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.calcBackProject([frame_hsv],[0,1],histogram,[0,180,0,256],1)\n",
    "    _,mask = cv2.threshold(mask,10,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(10,10))\n",
    "    mask = cv2.filter2D(mask,-1,kernel)\n",
    "\n",
    "    kernel1 = np.ones((7,7),np.uint8)\n",
    "    mask = cv2.morphologyEx(mask,cv2.MORPH_OPEN,kernel1)\n",
    "    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n",
    "    mask = cv2.bilateralFilter(mask,5,75,75)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f763e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxContour(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_area = 0\n",
    "    max_contour = None\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_contour = contour\n",
    "\n",
    "    return max_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f52c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawDefects(frame_with_rect,maxContour,hull):\n",
    "    defects = cv2.convexityDefects(maxContour,hull)\n",
    "\n",
    "    for i in range(defects.shape[0]):\n",
    "        s,e,f,d = defects[i,0]\n",
    "        start = tuple(maxContour[s][0])\n",
    "        end = tuple(maxContour[e][0])\n",
    "        far = tuple(maxContour[f][0])\n",
    "        cv2.line(frame_with_rect,start,far,[255,0,0],2)\n",
    "        cv2.line(frame_with_rect,far,end,[0,255,0],2)\n",
    "        cv2.circle(frame_with_rect,far,5,[0,0,255],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "856dfb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCentroid(contour):\n",
    "    M = cv2.moments(contour)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    return cx,cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22551a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_point(defects, contour, centroid):\n",
    "    if defects is not None and centroid is not None:\n",
    "        s = defects[:, 0][:, 0]\n",
    "        cx, cy = centroid\n",
    "\n",
    "        x = np.array(contour[s][:, 0][:, 0], dtype=float)\n",
    "        y = np.array(contour[s][:, 0][:, 1], dtype=float)\n",
    "\n",
    "        xp = cv2.pow(cv2.subtract(x, cx), 2)\n",
    "        yp = cv2.pow(cv2.subtract(y, cy), 2)\n",
    "        dist = cv2.sqrt(cv2.add(xp, yp))\n",
    "\n",
    "        dist_max_i = np.argmax(dist)\n",
    "\n",
    "        if dist_max_i < len(s):\n",
    "            farthest_defect = s[dist_max_i]\n",
    "            farthest_point = tuple(contour[farthest_defect][0])\n",
    "            return farthest_point\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de2d9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropCharacter(canvas):\n",
    "    print(canvas.shape)\n",
    "    for i in range(canvas.shape[0]):\n",
    "        for j in range(canvas.shape[1]):\n",
    "            print('i {i}',i)\n",
    "            print('j {j}',j)\n",
    "\n",
    "            if canvas[i,j]!=255:\n",
    "                canvas = canvas[i:canvas.shape[0],:]\n",
    "\n",
    "    return canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ecf85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getROI(canvas):\n",
    "    # Invert the canvas to make the characters white on a black background.\n",
    "    gray = cv2.bitwise_not(canvas)\n",
    "    \n",
    "    # Apply a binary threshold to obtain a binary image with characters as white.\n",
    "    ret, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Find contours in the binary image.\n",
    "    ctrs, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Initialize a list to store areas and their corresponding contour indices.\n",
    "    areas = []\n",
    "\n",
    "    # Calculate the area of each contour's bounding box.\n",
    "    for i in range(len(ctrs)):\n",
    "        x, y, w, h = cv2.boundingRect(ctrs[i])\n",
    "        areas.append((w * h, i))\n",
    "\n",
    "    # Sort the areas in descending order.\n",
    "    areas.sort(reverse=True)\n",
    "    \n",
    "    if areas:\n",
    "        # Extract the bounding box of the largest area (first in the sorted list).\n",
    "        x, y, w, h = cv2.boundingRect(ctrs[areas[0][1]])\n",
    "        \n",
    "        # Draw a rectangle around the detected ROI on the canvas.\n",
    "        cv2.rectangle(canvas, (x, y), (x + w, y + h), (255, 255, 0), 1)\n",
    "        \n",
    "        # Extract the ROI from the inverted grayscale image.\n",
    "        roi = gray[y:y + h, x:x + w]\n",
    "        \n",
    "        # Return the ROI.\n",
    "        return roi\n",
    "    else:\n",
    "        # If no areas are found, return None.\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5d4e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictCharacter(roi, model):\n",
    "    img = cv2.resize(roi, (28, 28))\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    img = Image.fromarray(img)\n",
    "\n",
    "    # Convert the grayscale image to a single channel (1x28x28)\n",
    "    img = img.convert(\"L\")\n",
    "\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.5],\n",
    "        std=[0.5]\n",
    "    )\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "    p_img = preprocess(img)\n",
    "\n",
    "    model.eval()\n",
    "    p_img = p_img.unsqueeze(0)  # Add a batch dimension\n",
    "    output = model(p_img)\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27896263",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 115>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    113\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 116\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m256\u001b[39m):\n\u001b[0;32m     38\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 39\u001b[0m     y1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhist_normalized\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m i\n\u001b[0;32m     41\u001b[0m     y2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(hist_normalized[i])\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    canvas = np.zeros((720,1280), np.uint8)\n",
    "\n",
    "    far_points = []\n",
    "\n",
    "    pressed = False\n",
    "    isDrawing = False\n",
    "    madePrediction = False\n",
    "    # create a complete CNN\n",
    "    model = Net()\n",
    "\n",
    "    model.load_state_dict(torch.load('D:\\Downloads\\model_emnist.pt', map_location='cpu'))\n",
    "    while True:\n",
    "        _ , frame = cap.read()\n",
    "        frame = cv2.flip(frame,flipCode = 1)\n",
    "        originalFrame = copy.deepcopy(frame)\n",
    "        originalFrame = drawRectangles(originalFrame)\n",
    "        canvas[:,:] = 255\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key & 0xFF == ord('a'):\n",
    "            pressed = True\n",
    "            histogram = getHistogram(frame)\n",
    "            \n",
    "        # Inside the loop, after capturing the histogram:\n",
    "        if pressed:\n",
    "        # Normalize the histogram for visualization\n",
    "            hist_normalized = cv2.normalize(histogram, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        # Create an image to represent the histogram\n",
    "            hist_image = np.zeros((100, 256, 3), dtype=np.uint8)\n",
    "\n",
    "        # Draw the histogram on the image\n",
    "            for i in range(1, 256):\n",
    "                x1 = i - 1\n",
    "                y1 = 100 - int(hist_normalized[i - 1])\n",
    "                x2 = i\n",
    "                y2 = 100 - int(hist_normalized[i])\n",
    "                cv2.line(hist_image, (x1, y1), (x2, y2), (255, 255, 255), 1)\n",
    "\n",
    "    # Display the histogram image\n",
    "            cv2.imshow('Histogram', hist_image)\n",
    "\n",
    "\n",
    "            \n",
    "        if key & 0xFF == ord('d'):\n",
    "            isDrawing = True\n",
    "\n",
    "        if key & 0xFF == ord('c'):\n",
    "            canvas[:,:] = 255\n",
    "            isDrawing = False\n",
    "            far_points.clear()\n",
    "            madePrediction = False\n",
    "\n",
    "\n",
    "        if isDrawing:\n",
    "            if len(far_points)>100:\n",
    "                far_points.pop(0)\n",
    "            far_points.append(far)\n",
    "            for i in range(len(far_points)-1):\n",
    "                cv2.line(originalFrame, far_points[i], far_points[i+1], (255,5,255), 10)\n",
    "                cv2.line(canvas, far_points[i], far_points[i+1], (0,0,0), 10)\n",
    "\n",
    "        if key & 0xFF == ord('f'):\n",
    "            isDrawing = False\n",
    "            #canvas = cropCharacter(canvas)\n",
    "            #cv2.imshow('LeftCrop', canvas)\n",
    "            roi = getROI(canvas)\n",
    "            prediction = predictCharacter(roi, model)\n",
    "            print(prediction)\n",
    "            madePrediction = True\n",
    "            name = str(prediction) + '.jpg'\n",
    "            cv2.imwrite(name, roi)\n",
    "\n",
    "\n",
    "        if pressed:\n",
    "            mask = getMask(frame,histogram)\n",
    "            maxContour = getMaxContour(mask)\n",
    "            epsilon = 0.25*cv2.arcLength(maxContour,True) \n",
    "            approx = cv2.approxPolyDP(maxContour,epsilon,True)\n",
    "            hull = cv2.convexHull(maxContour,returnPoints = False)\n",
    "            drawDefects(originalFrame, maxContour, hull)\n",
    "            defects = cv2.convexityDefects(maxContour,hull)\n",
    "            far = farthest_point(defects, maxContour, getCentroid(maxContour))\n",
    "            cv2.circle(originalFrame,far,10,[0,200,255],-1)\n",
    "\n",
    "\n",
    "            #cv2.imshow('Mask', mask)\n",
    "            #cv2.imshow('Canvas', canvas)\n",
    "\n",
    "        if madePrediction:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            text = 'You wrote - ' + chr(prediction + 65)  # Include the letter you predicted\n",
    "            # Adjust the font scale to change the font size\n",
    "            font_scale = 2  # Change this value to adjust the font size\n",
    "\n",
    "            text_size = cv2.getTextSize(text, font, font_scale, 2)[0]  # Get the size of the text\n",
    "\n",
    "    # Adjust the position based on text size to keep it within the frame\n",
    "            text_x = max(10, (originalFrame.shape[1] - text_size[0]) // 2)  # Centered horizontally\n",
    "            text_y = max(100, originalFrame.shape[0] - 10)  # Place it near the bottom of the frame\n",
    "\n",
    "            cv2.putText(originalFrame, text, (text_x, text_y), font, font_scale, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        if key & 0xFF == ord('q'):\n",
    "            break\n",
    "        cv2.imshow('frame',originalFrame)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "543c0452",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m far \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Initialize far outside the isDrawing block\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     _, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     26\u001b[0m     frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(frame, flipCode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m     originalFrame \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(frame)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the coordinates and size of the fixed drawing area (square)\n",
    "draw_area_x = 100\n",
    "draw_area_y = 100\n",
    "draw_area_size = 200  # Adjust the size as needed\n",
    "\n",
    "# ... (Previous code for defining the drawing area)\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    canvas = np.zeros((720, 1280), np.uint8)\n",
    "\n",
    "    far_points = []\n",
    "\n",
    "    pressed = False\n",
    "    isDrawing = False\n",
    "    madePrediction = False\n",
    "    model = Net()\n",
    "\n",
    "    model.load_state_dict(torch.load('D:\\Downloads\\model_emnist.pt', map_location='cpu'))\n",
    "    \n",
    "    far = None  # Initialize far outside the isDrawing block\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip(frame, flipCode=1)\n",
    "    originalFrame = copy.deepcopy(frame)\n",
    "    originalFrame = drawRectangles(originalFrame)\n",
    "    canvas[:,:] = 255\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    # Draw the fixed drawing area as a square\n",
    "    cv2.rectangle(originalFrame, (draw_area_x, draw_area_y),\n",
    "                  (draw_area_x + draw_area_size, draw_area_y + draw_area_size), (0, 0, 0), 2)\n",
    "\n",
    "    if key & 0xFF == ord('d'):\n",
    "        # Start drawing mode when 'd' key is pressed\n",
    "        isDrawing = True\n",
    "        far_points.clear()  # Clear the previous drawing points\n",
    "\n",
    "    if key & 0xFF == ord('c'):\n",
    "        # Clear the entire canvas (including the fixed drawing area)\n",
    "        canvas[:,:] = 255\n",
    "        madePrediction = False\n",
    "\n",
    "    if key & 0xFF == ord('f'):\n",
    "        # End drawing mode when 'f' key is pressed\n",
    "        isDrawing = False\n",
    "        pressed = True  # Indicate that drawing is completed and ready for prediction\n",
    "\n",
    "    if isDrawing:\n",
    "        if len(far_points) > 100:\n",
    "            far_points.pop(0)\n",
    "        far_points.append(far)\n",
    "        for i in range(len(far_points) - 1):\n",
    "            cv2.line(originalFrame, far_points[i], far_points[i + 1], (255, 5, 255), 10)\n",
    "            cv2.line(canvas, far_points[i], far_points[i + 1], (0, 0, 0), 10)\n",
    "\n",
    "    if pressed:\n",
    "        mask = getMask(frame, histogram)\n",
    "        maxContour = getMaxContour(mask)\n",
    "        epsilon = 0.25 * cv2.arcLength(maxContour, True)\n",
    "        approx = cv2.approxPolyDP(maxContour, epsilon, True)\n",
    "        hull = cv2.convexHull(maxContour, returnPoints=False)\n",
    "        drawDefects(originalFrame, maxContour, hull)\n",
    "        defects = cv2.convexityDefects(maxContour, hull)\n",
    "        far = farthest_point(defects, maxContour, getCentroid(maxContour))\n",
    "        cv2.circle(originalFrame, far, 10, [0, 200, 255], -1)\n",
    "\n",
    "    if madePrediction:\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = 'You wrote - ' + chr(prediction + 65)  # Include the letter you predicted\n",
    "        font_scale = 2  # Adjust the font size\n",
    "        text_size = cv2.getTextSize(text, font, font_scale, 2)[0]\n",
    "        text_x = max(10, (originalFrame.shape[1] - text_size[0]) // 2)\n",
    "        text_y = max(100, originalFrame.shape[0] - 10)\n",
    "\n",
    "        cv2.putText(originalFrame, text, (text_x, text_y), font, font_scale, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "    cv2.imshow('frame', originalFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ba54d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
